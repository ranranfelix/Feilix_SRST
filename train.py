import json
import os
from pathlib import Path
from pprint import pprint
import matplotlib.pyplot as plt
import torch.nn as nn
import torch.nn.functional as F    # â† ç¡®ä¿æœ‰è¿™ä¸€è¡Œ
from Net.AdaptiveCNNBiLSTM import AdaptiveCNNBiLSTM

os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"
import decode
import decode.utils
import decode.neuralfitter.train.live_engine
import torch

path = Path('')
import copy
from pathlib import Path
import decode.evaluation
import decode.neuralfitter
import decode.neuralfitter.coord_transform
import decode.neuralfitter.utils
import decode.simulation
from decode.neuralfitter.train.random_simulation import setup_random_simulation
from decode.neuralfitter.utils import log_train_val_progress
from decode.utils.checkpoint import CheckPoint

def convert_to_serializable(obj):
    """å°† Tensor ç­‰å¯¹è±¡è½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„æ ¼å¼"""
    if isinstance(obj, torch.Tensor):
        return obj.item() if obj.numel() == 1 else obj.tolist()
    elif isinstance(obj, dict):
        return {k: convert_to_serializable(v) for k, v in obj.items()}
    elif isinstance(obj, (list, tuple)):
        return [convert_to_serializable(item) for item in obj]
    else:
        return obj


def setup_trainer(simulator_train, simulator_test, logger, model_out, ckpt_path, device, param):
    """Set model, optimiser, loss and schedulers"""
    models_available = {
        'SigmaMUNet': decode.neuralfitter.models.SigmaMUNet,
        'DoubleMUnet': decode.neuralfitter.models.model_param.DoubleMUnet,
        'SimpleSMLMNet': decode.neuralfitter.models.model_param.SimpleSMLMNet,
    }

    model = models_available[param.HyperParameter.architecture]
    # print("ch_in:%d" % param.HyperParameter.channels_in)
    model = model.parse(param)

    model_ls = decode.utils.model_io.LoadSaveModel(model,
                                                   output_file=model_out)

    model = model_ls.load_init()
    model = model.to(torch.device(device))

    # Small collection of optimisers
    """Checkpointing"""
    checkpoint = CheckPoint(path=ckpt_path)

    """Setup gradient modification"""
    grad_mod = param.HyperParameter.grad_mod

    """Log the model"""
    try:
        dummy = torch.rand((2, param.HyperParameter.channels_in,
                            *param.Simulation.img_size), requires_grad=False).to(
            torch.device(device))
        logger.add_graph(model, dummy)

    except:
        print("Did not log graph.")
        # raise RuntimeError("Your dummy input is wrong. Please update it.")

    """Transform input data, compute weight mask and target data"""
    frame_proc = decode.neuralfitter.scale_transform.AmplitudeRescale.parse(param)
    bg_frame_proc = None

    if param.HyperParameter.emitter_label_photon_min is not None:
        em_filter = decode.neuralfitter.em_filter.PhotonFilter(
            param.HyperParameter.emitter_label_photon_min)
    else:
        em_filter = decode.neuralfitter.em_filter.NoEmitterFilter()

    tar_frame_ix_train = (0, 0)
    tar_frame_ix_test = (0, param.TestSet.test_size)

    """Setup Target generator consisting possibly multiple steps in a transformation sequence."""
    tar_gen = decode.neuralfitter.utils.processing.TransformSequence(
        [
            decode.neuralfitter.target_generator.ParameterListTarget(
                n_max=param.HyperParameter.max_number_targets,
                xextent=param.Simulation.psf_extent[0],
                yextent=param.Simulation.psf_extent[1],
                ix_low=tar_frame_ix_train[0],
                ix_high=tar_frame_ix_train[1],
                squeeze_batch_dim=True),

            decode.neuralfitter.target_generator.DisableAttributes.parse(param),

            decode.neuralfitter.scale_transform.ParameterListRescale(
                phot_max=param.Scaling.phot_max,
                z_max=param.Scaling.z_max,
                bg_max=param.Scaling.bg_max)
        ])

    # setup target for test set in similar fashion, however test-set is static.
    tar_gen_test = copy.deepcopy(tar_gen)
    tar_gen_test.com[0].ix_low = tar_frame_ix_test[0]
    tar_gen_test.com[0].ix_high = tar_frame_ix_test[1]
    tar_gen_test.com[0].squeeze_batch_dim = False
    tar_gen_test.com[0].sanity_check()

    if param.Simulation.mode == 'acquisition':
        train_ds = decode.neuralfitter.dataset.SMLMLiveDataset(
            simulator=simulator_train,
            em_proc=em_filter,
            frame_proc=frame_proc,
            bg_frame_proc=bg_frame_proc,
            tar_gen=tar_gen, weight_gen=None,
            frame_window=param.HyperParameter.channels_in,
            pad=None, return_em=True)

        train_ds.sample(True)

    elif param.Simulation.mode == 'samples':
        train_ds = decode.neuralfitter.dataset.SMLMLiveSampleDataset(
            simulator=simulator_train,
            em_proc=em_filter,
            frame_proc=frame_proc,
            bg_frame_proc=bg_frame_proc,
            tar_gen=tar_gen,
            weight_gen=None,
            frame_window=param.HyperParameter.channels_in,
            return_em=False,
            ds_len=param.HyperParameter.pseudo_ds_size)

    test_ds = decode.neuralfitter.dataset.SMLMAPrioriDataset(
        simulator=simulator_test,
        em_proc=em_filter,
        frame_proc=frame_proc,
        bg_frame_proc=bg_frame_proc,
        tar_gen=tar_gen_test, weight_gen=None,
        frame_window=param.HyperParameter.channels_in,
        pad=None, return_em=True)

    test_ds.sample(True)

    """Set up post processor"""
    if param.PostProcessing is None:
        post_processor = decode.neuralfitter.post_processing.NoPostProcessing(xy_unit='px',
                                                                              px_size=param.Camera.px_size)

    elif param.PostProcessing == 'LookUp':
        post_processor = decode.neuralfitter.utils.processing.TransformSequence([

            decode.neuralfitter.scale_transform.InverseParamListRescale(
                phot_max=param.Scaling.phot_max,
                z_max=param.Scaling.z_max,
                bg_max=param.Scaling.bg_max),

            decode.neuralfitter.coord_transform.Offset2Coordinate.parse(param),

            decode.neuralfitter.post_processing.LookUpPostProcessing(
                raw_th=param.PostProcessingParam.raw_th,
                pphotxyzbg_mapping=[0, 1, 2, 3, 4, 9],
                xy_unit='px',
                px_size=param.Camera.px_size)
        ])

    elif param.PostProcessing in ('SpatialIntegration', 'NMS'):  # NMS as legacy support
        post_processor = decode.neuralfitter.utils.processing.TransformSequence([

            decode.neuralfitter.scale_transform.InverseParamListRescale(
                phot_max=param.Scaling.phot_max,
                z_max=param.Scaling.z_max,
                bg_max=param.Scaling.bg_max),

            decode.neuralfitter.coord_transform.Offset2Coordinate.parse(param),

            decode.neuralfitter.post_processing.SpatialIntegration(
                raw_th=param.PostProcessingParam.raw_th,
                xy_unit='px',
                px_size=param.Camera.px_size)
        ])

    else:
        raise NotImplementedError

    """Evaluation Specification"""
    matcher = decode.evaluation.match_emittersets.GreedyHungarianMatching.parse(param)

    return train_ds, test_ds, model, model_ls, grad_mod, post_processor, matcher, checkpoint


from typing import Union, Tuple
import numpy as np
from torch import distributions
from decode.simulation import psf_kernel


class LossFunc():
    def __init__(self, xextent: tuple, yextent: tuple, img_shape: tuple, device: Union[str, torch.device], psf):
        super().__init__()
        self._psf_loss = torch.nn.MSELoss(reduction='none')
        self._offset2coord = psf_kernel.DeltaPSF(xextent=xextent, yextent=yextent, img_shape=img_shape)
        self.device = device
        self._psf_img_gen = decode.simulation.Simulation(psf=psf)
        self.xextent = xextent
        self.yextent = xextent
        self.img_shape = img_shape

    def log(self, loss_val):
        return loss_val.mean().item(), {'gmm': loss_val[:, 0].mean().item(),
                                        'p': loss_val[:, 1].mean().item(),
                                        'bg': loss_val[:, 2].mean().item(),
                                        # 'img': loss_val[:, -1].mean().item()
                                        }

    def CELoss(self, P, em_tar, tar_mask) -> torch.Tensor:
        S = torch.zeros([len(em_tar), param.Simulation.img_size[0], param.Simulation.img_size[1]]).to(self.device)
        if tar_mask.sum():
            for i, tar in enumerate(em_tar):
                tar = tar.xyz_px.to(self.device)
                tar = torch.round(tar[:, [0, 1]], decimals=0)
                tar = (tar.transpose(0, 1)).int()
                tar = (tar[0], tar[1])
                S[i].index_put(tar, torch.ones(tar[0].size()).to(self.device))
        loss = 0
        loss += -(S * torch.log(P) + (1 - S) * torch.log(1 - P))
        loss = loss.sum(-1).sum(-1)
        return loss

    def Loss_Count(self, P, tar_mask):
        loss = 0
        prob_mean = P.sum(-1).sum(-1)
        prob_var = (P - P ** 2).sum(-1).sum(-1)
        loss += 1 / 2 * ((tar_mask.sum(-1) - prob_mean) ** 2) / prob_var + 1 / 2 * torch.log(2 * np.pi * prob_var)
        num_emitters = torch.clamp(tar_mask.sum(-1), min=1.0)
        loss = loss / num_emitters  # â† é™¤ä»¥emitteræ•°é‡normalize
        # loss = loss * tar_mask.sum(-1)
        return loss

    def Loss_Loc(self, P, pxyz_mu, pxyz_sig, pxyz_tar, mask):
        batch_size = P.size(0)
        prob_normed = P / (P.sum(-1).sum(-1)[:, None, None])

        p_inds = tuple((P + 1).nonzero().transpose(1, 0))

        pxyz_mu = pxyz_mu[p_inds[0], :, p_inds[1], p_inds[2]]
        self._offset2coord._bin_ctr_x = self._offset2coord._bin_ctr_x.to(pxyz_mu.device)
        self._offset2coord._bin_ctr_y = self._offset2coord._bin_ctr_y.to(pxyz_mu.device)
        pxyz_mu[:, 1] = pxyz_mu[:, 1] + self._offset2coord.bin_ctr_x[p_inds[1]]
        pxyz_mu[:, 2] = pxyz_mu[:, 2] + self._offset2coord.bin_ctr_y[p_inds[2]]

        pxyz_mu = pxyz_mu.reshape(batch_size, 1, -1, 4)
        pxyz_sig = pxyz_sig[p_inds[0], :, p_inds[1], p_inds[2]].reshape(batch_size, 1, -1, 4)
        PXYZ = pxyz_tar.reshape(batch_size, -1, 1, 4).repeat_interleave(self.img_shape[0] * self.img_shape[1], 2)

        numerator = -1 / 2 * ((PXYZ - pxyz_mu) ** 2)
        denominator = (pxyz_sig ** 2)
        log_p_gauss_4d = (numerator / denominator).sum(3) - 1 / 2 * (torch.log(2 * np.pi * denominator[:, :, :, 0]) +
                                                                     torch.log(2 * np.pi * denominator[:, :, :, 1]) +
                                                                     torch.log(2 * np.pi * denominator[:, :, :, 2]) +
                                                                     torch.log(2 * np.pi * denominator[:, :, :, 3]))

        gauss_coef = prob_normed.reshape(batch_size, 1, self.img_shape[0] * self.img_shape[1])
        gauss_coef_logits = torch.log(gauss_coef)
        gauss_coef_logmax = torch.log_softmax(gauss_coef_logits, dim=2)
        gmm_log = torch.logsumexp(log_p_gauss_4d + gauss_coef_logmax, dim=2)

        result = -(gmm_log * mask).sum(-1)
    
    # ============ æ·»åŠ normalize ============
        num_emitters = torch.clamp(mask.sum(-1), min=1.0)
        result = result / num_emitters
    # ========================================
    
        return result

    def Loss_psf(self, psf_img, psf_gt):
        if psf_gt.dim() == 4:
            psf_gt = psf_gt[:, 2]
        loss = self._psf_loss(psf_img, psf_gt)
        loss = loss.sum(-1).sum(-1)
        return loss

    def get_psf_gt(self, em_tar):
        for i, em in enumerate(em_tar):
            tmp, _ = self._psf_img_gen.forward(em)
            tmp = tmp.to(self.device)
            if i == 0:
                psf_gt = tmp
            else:
                psf_gt = torch.cat((psf_gt, tmp), dim=0)
        return psf_gt

    def norm(self, nobg):
        ret = []
        for tmp in nobg:
            tmp = (tmp - torch.min(tmp)) / (torch.max(tmp) - torch.min(tmp))
            ret.append(tmp)
        return torch.stack(ret, dim=0)

    def final_loss(self, output, target, nobg, em_tar=None):
        tar_param, tar_mask, tar_bg = target
        P = output[:, 0]
        pxyz_mu = output[:, 1:5]
        pxyz_sig = output[:, 5:9]
        bg_img = output[:, 9]
        # psf_img = output[:, -1]
        # nobg = self.norm(nobg)
        # psf_gt = self.get_psf_gt(em_tar)

        loss = torch.stack((self.Loss_Loc(P, pxyz_mu, pxyz_sig, tar_param, tar_mask), self.Loss_Count(P, tar_mask)),
                           dim=1)
        loss = torch.cat((loss, self._psf_loss(bg_img, tar_bg).sum(-1).sum(-1).unsqueeze(1)), dim=1)
        # loss = torch.cat((loss,self.Loss_psf(psf_img, nobg).unsqueeze(1)*0.0001),dim=1)
        return loss
# class FixedLossFunc():
#     """ä¿®å¤æ•°å€¼ç¨³å®šæ€§çš„æŸå¤±å‡½æ•°"""
#     def __init__(self, xextent: tuple, yextent: tuple, img_shape: tuple, 
#                  device, psf):
#         super().__init__()
#         self._psf_loss = torch.nn.MSELoss(reduction='none')
#         self._offset2coord = psf_kernel.DeltaPSF(xextent=xextent, yextent=yextent, 
#                                                   img_shape=img_shape)
#         self.device = device
#         self._psf_img_gen = decode.simulation.Simulation(psf=psf)
#         self.xextent = xextent
#         self.yextent = yextent
#         self.img_shape = img_shape

#     def log(self, loss_val):
#         return loss_val.mean().item(), {
#             'gmm': loss_val[:, 0].mean().item(),
#             'p': loss_val[:, 1].mean().item(),
#             'bg': loss_val[:, 2].mean().item(),
#         }

#     def Loss_Count(self, P, tar_mask):
#         prob_mean = P.sum(-1).sum(-1)
#         prob_var = (P - P ** 2).sum(-1).sum(-1)
        
#         # ã€ä¿®å¤ã€‘æ·»åŠ æ•°å€¼ç¨³å®šæ€§
#         prob_var = torch.clamp(prob_var, min=1e-6)
        
#         loss = 1 / 2 * ((tar_mask.sum(-1) - prob_mean) ** 2) / prob_var + \
#                1 / 2 * torch.log(2 * np.pi * prob_var)
#         loss = loss * torch.clamp(tar_mask.sum(-1), min=1.0)  # é¿å…ä¹˜ä»¥0
#         return loss

#     def Loss_Loc(self, P, pxyz_mu, pxyz_sig, pxyz_tar, mask):
#         batch_size = P.size(0)
        
#         # ã€ä¿®å¤ã€‘æ·»åŠ epsiloné¿å…é™¤ä»¥0
#         prob_normed = P / (P.sum(-1).sum(-1)[:, None, None] + 1e-10)

#         p_inds = tuple((P + 1).nonzero(as_tuple=False).transpose(1, 0))
        
#         # å¦‚æœæ²¡æœ‰æœ‰æ•ˆä½ç½®ï¼Œè¿”å›0
#         if len(p_inds[0]) == 0:
#             return torch.zeros(batch_size).to(self.device)

#         pxyz_mu = pxyz_mu[p_inds[0], :, p_inds[1], p_inds[2]]
#         self._offset2coord._bin_ctr_x = self._offset2coord._bin_ctr_x.to(pxyz_mu.device)
#         self._offset2coord._bin_ctr_y = self._offset2coord._bin_ctr_y.to(pxyz_mu.device)
#         pxyz_mu[:, 1] = pxyz_mu[:, 1] + self._offset2coord.bin_ctr_x[p_inds[1]]
#         pxyz_mu[:, 2] = pxyz_mu[:, 2] + self._offset2coord.bin_ctr_y[p_inds[2]]

#         pxyz_mu = pxyz_mu.reshape(batch_size, 1, -1, 4)
#         pxyz_sig = pxyz_sig[p_inds[0], :, p_inds[1], p_inds[2]].reshape(batch_size, 1, -1, 4)
#         PXYZ = pxyz_tar.reshape(batch_size, -1, 1, 4).repeat_interleave(
#             self.img_shape[0] * self.img_shape[1], 2)

#         numerator = -1 / 2 * ((PXYZ - pxyz_mu) ** 2)
        
#         # ã€ä¿®å¤ã€‘é™åˆ¶sigmaçš„èŒƒå›´ï¼Œé¿å…æ•°å€¼é—®é¢˜
#         denominator = torch.clamp(pxyz_sig ** 2, min=1e-6, max=100.0)
        
#         log_p_gauss_4d = (numerator / denominator).sum(3) - 1 / 2 * (
#             torch.log(2 * np.pi * denominator[:, :, :, 0]) +
#             torch.log(2 * np.pi * denominator[:, :, :, 1]) +
#             torch.log(2 * np.pi * denominator[:, :, :, 2]) +
#             torch.log(2 * np.pi * denominator[:, :, :, 3])
#         )

#         gauss_coef = prob_normed.reshape(batch_size, 1, self.img_shape[0] * self.img_shape[1])
#         gauss_coef_logits = torch.log(gauss_coef + 1e-10)
#         gauss_coef_logmax = torch.log_softmax(gauss_coef_logits, dim=2)
#         gmm_log = torch.logsumexp(log_p_gauss_4d + gauss_coef_logmax, dim=2)

#         return -(gmm_log * mask).sum(-1)

#     def final_loss(self, output, target, nobg, em_tar=None):
#         tar_param, tar_mask, tar_bg = target
#         P = output[:, 0]
#         pxyz_mu = output[:, 1:5]
#         pxyz_sig = output[:, 5:9]
#         bg_img = output[:, 9]
        
#         loss_loc = self.Loss_Loc(P, pxyz_mu, pxyz_sig, tar_param, tar_mask)
#         loss_count = self.Loss_Count(P, tar_mask)
#         loss_bg = self._psf_loss(bg_img, tar_bg).sum(-1).sum(-1)
        
#         # ã€ä¿®å¤ã€‘æ£€æŸ¥å¹¶é™åˆ¶æŸå¤±å€¼
#         loss_loc = torch.clamp(loss_loc, max=10000.0)
#         loss_count = torch.clamp(loss_count, max=10000.0)
#         loss_bg = torch.clamp(loss_bg, max=1000.0)
        
#         loss = torch.stack((loss_loc, loss_count), dim=1)
#         loss = torch.cat((loss, loss_bg.unsqueeze(1)), dim=1)
        
#         # ã€è°ƒè¯•ã€‘æ‰“å°æŸå¤±ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
#         if torch.isnan(loss).any() or (loss > 50000).any():
#             print(f"WARNING: Loc={loss_loc.mean():.1f}, Count={loss_count.mean():.1f}, BG={loss_bg.mean():.1f}")
        
#         return loss


import torch
import time
from typing import Union

from tqdm import tqdm
from collections import namedtuple

from decode.neuralfitter.utils import log_train_val_progress
from decode.evaluation.utils import MetricMeter
class OverfittingMonitor:
    """ç§‘å­¦çš„è¿‡æ‹Ÿåˆç›‘æ§å™¨"""
    def __init__(self, patience=5, min_epochs=10):
        self.train_losses = []
        self.val_losses = []
        self.relative_gaps = []
        self.patience = patience
        self.min_epochs = min_epochs
        self.best_val_loss = float('inf')
        self.epochs_no_improve = 0
        
    def update(self, train_loss, val_loss):
        self.train_losses.append(train_loss)
        self.val_losses.append(val_loss)
        
        # è®¡ç®—ç›¸å¯¹é—´éš™
        if train_loss > 1e-6:
            relative_gap = abs(val_loss - train_loss) / train_loss
        else:
            relative_gap = 0.0
        self.relative_gaps.append(relative_gap)
        
        # Early stopping æ£€æµ‹
        if val_loss < self.best_val_loss:
            self.best_val_loss = val_loss
            self.epochs_no_improve = 0
        else:
            self.epochs_no_improve += 1
            
    def get_status(self, epoch):
        """å¤šç»´åº¦è¯„ä¼°è®­ç»ƒçŠ¶æ€"""
        # ğŸ‘‡ ä¿®æ”¹è¿™é‡Œï¼šå³ä½¿æ˜¯ç¬¬ä¸€ä¸ªepochä¹Ÿè¦è¿”å›metrics
        if len(self.train_losses) < 1:
            # å¦‚æœå®Œå…¨æ²¡æœ‰æ•°æ®ï¼Œè¿”å›ç©ºçŠ¶æ€
            return "â³ åˆå§‹åŒ–", {
                'train_loss': 0.0,
                'val_loss': 0.0,
                'absolute_gap': 0.0,
                'relative_gap': 0.0,
                'val_trend': 0.0,
                'gap_trend': 0.0,
            }
        
        train_loss = self.train_losses[-1]
        val_loss = self.val_losses[-1]
        relative_gap = self.relative_gaps[-1]
        
        # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
        metrics = {
            'train_loss': train_loss,
            'val_loss': val_loss,
            'absolute_gap': abs(val_loss - train_loss),
            'relative_gap': relative_gap,
            'val_trend': self._compute_trend(self.val_losses[-5:]) if len(self.val_losses) >= 2 else 0.0,
            'gap_trend': self._compute_trend(self.relative_gaps[-5:]) if len(self.relative_gaps) >= 2 else 0.0,
        }
        
        # ğŸ‘‡ ä¿®æ”¹åˆ¤æ–­æ¡ä»¶
        if epoch < self.min_epochs or len(self.train_losses) < 2:
            status = "â³ è®­ç»ƒä¸­ (æ ·æœ¬ä¸è¶³)"
        else:
            # å¤šç»´åº¦åˆ¤æ–­
            status = self._diagnose(train_loss, val_loss, relative_gap, epoch, metrics)
        
        return status, metrics
    
    def _compute_trend(self, values):
        """è®¡ç®—è¶‹åŠ¿: æ­£å€¼=ä¸Šå‡, è´Ÿå€¼=ä¸‹é™"""
        if len(values) < 2:
            return 0.0
        # ç®€å•çº¿æ€§å›å½’æ–œç‡
        n = len(values)
        x = list(range(n))
        x_mean = sum(x) / n
        y_mean = sum(values) / n
        slope = sum((x[i] - x_mean) * (values[i] - y_mean) for i in range(n)) / \
                (sum((x[i] - x_mean) ** 2 for i in range(n)) + 1e-8)
        return slope
    
    def _diagnose(self, train_loss, val_loss, relative_gap, epoch, metrics):
        """ç»¼åˆè¯Šæ–­"""
        # 1. æ¬ æ‹Ÿåˆæ£€æµ‹
        if train_loss > 0.5:  # æ ¹æ®ä½ çš„ä»»åŠ¡è°ƒæ•´è¿™ä¸ªé˜ˆå€¼
            return "âŒ æ¬ æ‹Ÿåˆ (è®­ç»ƒæŸå¤±è¿‡é«˜)"
        
        if epoch < self.min_epochs:
            return "â³ è®­ç»ƒä¸­ (æ ·æœ¬ä¸è¶³)"
        
        # 2. è¿‡æ‹Ÿåˆæ£€æµ‹ (å¤šæ¡ä»¶)
        overfitting_score = 0
        
        # æ¡ä»¶1: ç›¸å¯¹é—´éš™è¿‡å¤§
        if relative_gap > 0.25:
            overfitting_score += 3
        elif relative_gap > 0.15:
            overfitting_score += 2
        elif relative_gap > 0.10:
            overfitting_score += 1
            
        # æ¡ä»¶2: éªŒè¯æŸå¤±ä¸Šå‡è¶‹åŠ¿
        if metrics['val_trend'] > 0.001:
            overfitting_score += 2
            
        # æ¡ä»¶3: è®­ç»ƒ-éªŒè¯æŸå¤±èƒŒç¦»
        if len(self.train_losses) >= 3:
            train_trend = self._compute_trend(self.train_losses[-3:])
            if train_trend < -0.001 and metrics['val_trend'] > 0.001:
                overfitting_score += 2
        
        # æ¡ä»¶4: Early stopping ä¿¡å·
        if self.epochs_no_improve >= self.patience:
            overfitting_score += 2
            
        # ç»¼åˆåˆ¤æ–­
        if overfitting_score >= 6:
            return "âŒ ä¸¥é‡è¿‡æ‹Ÿåˆ"
        elif overfitting_score >= 4:
            return "âš ï¸  è¿‡æ‹Ÿåˆè­¦å‘Š"
        elif overfitting_score >= 2:
            return "âš ï¸  è½»å¾®è¿‡æ‹Ÿåˆ"
        elif relative_gap < 0.08:
            return "âœ… ä¼˜ç§€"
        elif relative_gap < 0.12:
            return "âœ… è‰¯å¥½"
        else:
            return "âš ï¸  æ³¨æ„ç›‘æ§"
    
    def should_stop(self, epoch):
        """æ˜¯å¦åº”è¯¥æå‰åœæ­¢"""
        if epoch < self.min_epochs:
            return False
        return self.epochs_no_improve >= self.patience
    
    def get_summary(self):
        """ç”Ÿæˆè®­ç»ƒæ€»ç»“"""
        if len(self.train_losses) <= 1:
            return {}
        
        valid_train = [l for l in self.train_losses[1:] if l > 0]
        valid_val = self.val_losses[1:]
        valid_gaps = [g for g in self.relative_gaps[1:] if g >= 0]
        
        if len(valid_train) == 0:
            return {}
        
        return {
            'avg_train_loss': sum(valid_train) / len(valid_train),
            'avg_val_loss': sum(valid_val) / len(valid_val),
            'avg_relative_gap': sum(valid_gaps) / len(valid_gaps),
            'min_val_loss': min(valid_val),
            'final_train_loss': self.train_losses[-1],
            'final_val_loss': self.val_losses[-1],
            'final_relative_gap': self.relative_gaps[-1],
            'best_epoch': valid_val.index(min(valid_val)) + 1,
            'convergence_score': self._compute_convergence_score()
        }
    
    def _compute_convergence_score(self):
        """æ”¶æ•›è´¨é‡è¯„åˆ† (0-100)"""
        if len(self.relative_gaps) < 5:
            return 0
        
        score = 100
        
        # æ‰£åˆ†é¡¹
        final_gap = self.relative_gaps[-1]
        if final_gap > 0.25:
            score -= 40
        elif final_gap > 0.15:
            score -= 20
        elif final_gap > 0.10:
            score -= 10
            
        # è¶‹åŠ¿æ‰£åˆ†
        gap_trend = self._compute_trend(self.relative_gaps[-10:])
        if gap_trend > 0.01:
            score -= 20
            
        # æ³¢åŠ¨æ‰£åˆ†
        recent_gaps = self.relative_gaps[-10:]
        if len(recent_gaps) > 0:
            gap_std = (sum((g - sum(recent_gaps)/len(recent_gaps))**2 for g in recent_gaps) / len(recent_gaps)) ** 0.5
            if gap_std > 0.05:
                score -= 15
        
        return max(0, score)


def train(model, optimizer, loss, dataloader, grad_rescale, grad_mod, epoch, device, logger) -> float:
    model.train()
    tqdm_enum = tqdm(dataloader, total=len(dataloader), smoothing=0.)
    t0 = time.time()
    loss_epoch = MetricMeter()

    for batch_num, (x, y_tar, weight, em_tar, nobg) in enumerate(tqdm_enum):
        t_data = time.time() - t0
        x, y_tar, weight, nobg = ship_device([x, y_tar, weight, nobg], device)
        y_out = model(x)

        # ğŸ‘‡ ä¿å­˜åŸå§‹æŸå¤±ç”¨äºè®°å½•
        loss_val_original = loss.final_loss(y_out, y_tar, nobg, em_tar)
        loss_val = loss_val_original  # ç”¨äºåå‘ä¼ æ’­çš„æŸå¤±

        if grad_rescale:
            weight, _, _ = model.rescale_last_layer_grad(loss_val, optimizer)
            loss_val = loss_val * weight  # åªä¿®æ”¹ç”¨äºåå‘ä¼ æ’­çš„æŸå¤±

        optimizer.zero_grad()
        loss_val.mean().backward()

        if grad_mod:
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.03, norm_type=2)

        optimizer.step()

        t_batch = time.time() - t0

        # ğŸ‘‡ ä½¿ç”¨åŸå§‹æŸå¤±è®¡ç®—æŒ‡æ ‡ï¼Œä¸æ˜¯ç¼©æ”¾åçš„
        loss_mean, loss_cmp = loss.log(loss_val_original)
        del loss_val, loss_val_original
        loss_epoch.update(loss_mean)
        
        tqdm_enum.set_description(f"E: {epoch} - t: {t_batch:.2} - t_dat: {t_data:.2} - L: {loss_mean:.3} \
                                  Lgmm: {loss_cmp['gmm']:.3}, Lp: {loss_cmp['p']:.3}, Lbg: {loss_cmp['bg']:.3}")
        t0 = time.time()

    log_train_val_progress.log_train(loss_p_batch=loss_epoch.vals, loss_mean=loss_epoch.mean, logger=logger, step=epoch)

    return loss_epoch.mean

from collections import namedtuple  # ç¡®ä¿namedtupleå¯¼å…¥

from collections import namedtuple
_val_return = namedtuple("network_output", ["loss", "x", "y_out", "y_tar", "weight", "em_tar"])

from collections import namedtuple
_val_return = namedtuple("network_output", ["loss", "x", "y_out", "y_tar", "weight", "em_tar"])

def test_simple(model, loss, dataloader, epoch, device):
    """ç®€åŒ–çš„æµ‹è¯•å‡½æ•° - ä¸ä½¿ç”¨MC Dropout"""
    model.eval()  # å…³é—­dropout
    
    x_ep, y_out_ep, y_tar_ep, weight_ep, em_tar_ep = [], [], [], [], []
    loss_cmp_ep = []
    
    tqdm_enum = tqdm(dataloader, total=len(dataloader), smoothing=0.)
    
    with torch.no_grad():
        for batch_num, (x, y_tar, weight, em_tar, nobg) in enumerate(tqdm_enum):
            x, y_tar, weight, nobg = ship_device([x, y_tar, weight, nobg], device)
            
            # ç›´æ¥é¢„æµ‹
            y_out = model(x)
            
            # è®¡ç®—æŸå¤±
            loss_val = loss.final_loss(y_out, y_tar, nobg, em_tar)
            
            # å­˜å‚¨ç»“æœ
            loss_cmp_ep.append(loss_val.detach().cpu())
            x_ep.append(x.cpu())
            y_out_ep.append(y_out.detach().cpu())
            
            if isinstance(y_tar, tuple):
                y_tar_cpu = tuple(t.cpu() if isinstance(t, torch.Tensor) else t for t in y_tar)
                y_tar_ep.append(y_tar_cpu)
            else:
                y_tar_ep.append(y_tar.cpu() if isinstance(y_tar, torch.Tensor) else y_tar)
            
            weight_ep.append(weight.cpu() if isinstance(weight, torch.Tensor) else weight)
            em_tar_ep.append(em_tar)
    
    loss_cmp_ep = torch.cat(loss_cmp_ep, 0)
    x_ep = torch.cat(x_ep, 0)
    y_out_ep = torch.cat(y_out_ep, 0)
    
    return loss_cmp_ep.mean(), _val_return(
        loss=loss_cmp_ep, x=x_ep, y_out=y_out_ep,
        y_tar=y_tar_ep, weight=weight_ep, em_tar=em_tar_ep
    )
def ship_device(x, device: Union[str, torch.device]):
    if x is None:
        return x

    elif isinstance(x, torch.Tensor):
        return x.to(device)

    elif isinstance(x, (tuple, list)):
        x = [ship_device(x_el, device) for x_el in x]  # a nice little recursion that worked at the first try
        return x

    elif device != 'cpu':
        raise NotImplementedError(f"Unsupported data type for shipping from host to CUDA device.")
    # ============ åœ¨è¿™é‡Œæ·»åŠ å®Œæ•´çš„æ¨¡å‹å®šä¹‰ ============

class SimpleConvLSTMCell(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(SimpleConvLSTMCell, self).__init__()
        self.hidden_channels = out_channels
        self.conv = nn.Conv2d(in_channels, 4 * out_channels, kernel_size=3, padding=1)

    def forward(self, x, hidden_state):
        h_cur, c_cur = hidden_state
        h_t = torch.cat([h_cur, x], dim=1)
        h_t = F.elu(self.conv(h_t))
        
        i, f, o, g = torch.split(h_t, self.hidden_channels, dim=1)
        c_next = torch.sigmoid(f) * c_cur + torch.sigmoid(i) * torch.tanh(g)
        h_next = torch.sigmoid(o) * torch.tanh(c_next)
        return h_next, c_next

    def init_hidden(self, batch_size, tensor_size, device):
        h, w = tensor_size
        return (
            torch.zeros(batch_size, self.hidden_channels, h, w).to(device),
            torch.zeros(batch_size, self.hidden_channels, h, w).to(device)
        )


class SimpleCNNBiLSTM(nn.Module):
    """ç®€åŒ–ç‰ˆæ¨¡å‹ - å®Œå…¨å…³é—­dropoutç”¨äºè°ƒè¯•"""
    ch_out = 11
    out_channels_heads = (1, 4, 4, 1)
    sigmoid_ch_ix = [0, 1, 5, 6, 7, 8, 9]
    tanh_ch_ix = [2, 3, 4]

    def __init__(self, in_channels=1, out_channels=11, depth=2, seq_len=5, 
                 initial_features=48, pad_convs=False, sigma_eps_default=0.005, **kwargs):
        super(SimpleCNNBiLSTM, self).__init__()
        
        self.sigma_eps_default = sigma_eps_default
        self.initial_features = initial_features
        self.seq_len = seq_len
        
        import Net.Unet as Unet
        
        # æ ¸å¿ƒç½‘ç»œ
        self.forward_layer = SimpleConvLSTMCell(2 * initial_features, initial_features)
        self.backward_layer = SimpleConvLSTMCell(2 * initial_features, initial_features)
        
        self.unet1 = Unet.Unet(in_channels, initial_features, depth=depth, pad_convs=pad_convs)
        self.unet2 = Unet.Unet(3 * initial_features, initial_features, depth=depth, pad_convs=pad_convs)
        
        first_half_len = seq_len // 2
        latter_half_len = seq_len - 1 - first_half_len
        
        if first_half_len > 0:
            self.union_firsthalf = Unet.Unet(first_half_len * initial_features, initial_features, depth=depth, pad_convs=pad_convs)
        else:
            self.union_firsthalf = None
            
        if latter_half_len > 0:
            self.union_latterhalf = Unet.Unet(latter_half_len * initial_features, initial_features, depth=depth, pad_convs=pad_convs)
        else:
            self.union_latterhalf = None
        
        self.add_conv = nn.Sequential(
            nn.Conv2d(3 * initial_features, initial_features, 3, padding=1),
            nn.ELU()
        )
        
        # è¾“å‡ºå¤´
        self.outconvlist = nn.ModuleList([
            nn.Sequential(
                nn.Conv2d(initial_features, initial_features, 3, padding=1),
                nn.ELU(),
                nn.Conv2d(initial_features, ch, 1)
            ) for ch in self.out_channels_heads
        ])
        
        print("âœ“ SimpleCNNBiLSTMåˆå§‹åŒ–æˆåŠŸ - Dropoutå…³é—­")

    def forward(self, x, hidden_state=None):
        device = x.device
        x = x.unsqueeze(2)
        
        if hidden_state is None:
            h1, c1 = self.forward_layer.init_hidden(x.size(0), (x.size(3), x.size(4)), device)
            h2, c2 = self.backward_layer.init_hidden(x.size(0), (x.size(3), x.size(4)), device)
        
        # UNetç‰¹å¾æå–
        firstlayer = [self.unet1(x[:, t, :, :, :]) for t in range(self.seq_len)]
        
        # BiLSTM
        forward_out = []
        for t in range(self.seq_len):
            h1, c1 = self.forward_layer(firstlayer[t], [h1, c1])
            forward_out.append([h1, c1])
        
        backward_out = []
        for t in range(self.seq_len - 1, -1, -1):
            h2, c2 = self.backward_layer(firstlayer[t], [h2, c2])
            backward_out.append([h2, c2])
        backward_out = backward_out[::-1]
        
        # æ‹¼æ¥
        tar = self.seq_len // 2
        combined = []
        for t in range(self.seq_len):
            o = torch.cat([firstlayer[t], forward_out[t][0], backward_out[t][0]], dim=1)
            combined.append(self.add_conv(o))
        
        # Union
        first_half_len = tar
        latter_half_len = self.seq_len - 1 - tar
        
        if first_half_len > 0 and self.union_firsthalf is not None:
            o1 = self.union_firsthalf(torch.cat(combined[:first_half_len], dim=1))
        else:
            o1 = torch.zeros(combined[tar].shape, device=device)
        
        if latter_half_len > 0 and self.union_latterhalf is not None:
            o2 = self.union_latterhalf(torch.cat(combined[self.seq_len-1:tar:-1], dim=1))
        else:
            o2 = torch.zeros(combined[tar].shape, device=device)
        
        # æœ€ç»ˆå¤„ç†
        o = self.unet2(torch.cat([o1, combined[tar], o2], dim=1))
        
        # è¾“å‡º
        o_heads = [outconv(o) for outconv in self.outconvlist]
        o = torch.cat(o_heads, dim=1)
        
        # æ¿€æ´»
        o[:, [0]] = torch.clamp(o[:, [0]], min=-8., max=8.)
        o[:, self.sigmoid_ch_ix] = torch.sigmoid(o[:, self.sigmoid_ch_ix])
        o[:, self.tanh_ch_ix] = torch.tanh(o[:, self.tanh_ch_ix])
        o[:, slice(5, 9)] = o[:, slice(5, 9)] * 3 + self.sigma_eps_default
        
        return o


if __name__ == '__main__':
    import datetime
    from decode.utils import param_io
    import decode.utils.calibration_io
    
    print("="*80)
    print("ğŸ”¬ åŒèºæ—‹PSFè®­ç»ƒè„šæœ¬")
    print(f"â° å¼€å§‹æ—¶é—´: {datetime.datetime.now()}")
    print("="*80)
    
    # ========== ç¬¬1æ­¥ï¼šåŠ è½½å‚æ•° ==========
    param_file = 'network/experiment1/param_run.yaml'
    print(f"\n[1/7] åŠ è½½å‚æ•°: {param_file}")
    param = param_io.load_params(param_file)
    param.Meta.version = decode.utils.bookkeeping.decode_state()
    
    # ========== ç¬¬2æ­¥ï¼š- å…ˆè®¾ç½®PSFç±»å‹ ==========
    print(f"\n[2/7] é…ç½®åŒèºæ—‹PSF")
    calibration_file = "D:/Projects/train/psfmod/spline_calibration_3d_dh_3dcal.mat"
    param.InOut.calibration_file = calibration_file
    
    # æ˜¾å¼è®¾ç½®PSFç±»å‹ï¼ˆåŸæ¥ç¼ºå°‘è¿™ä¸ªï¼ï¼‰
    param.Simulation.psf_type = decode.utils.calibration_io.SMAPSplineCoefficient(
        calib_file=calibration_file
    )
    print(f"  âœ“ PSFç±»å‹: {type(param.Simulation.psf_type).__name__}")
    print(f"  âœ“ PSFæ–‡ä»¶: {calibration_file}")
    
    # ========== ç¬¬3æ­¥ï¼šç°åœ¨æ‰æ‰§è¡Œautoset_scalingï¼ˆåŸºäºæ­£ç¡®çš„PSFï¼‰==========
    print(f"\n[3/7] é‡æ–°è®¡ç®—scalingå‚æ•°ï¼ˆåŸºäºåŒèºæ—‹PSFï¼‰")
    param = decode.utils.param_io.autoset_scaling(param)
    print(f"  âœ“ z_max: {param.Scaling.z_max}")
    print(f"  âœ“ phot_max: {param.Scaling.phot_max}")
    print(f"  âœ“ input_scale: {param.Scaling.input_scale}")
    
    # ========== ç¬¬4æ­¥ï¼šé™ä½å‚æ•°é˜²æ­¢GPU OOM ==========
    print(f"\n[4/7] ä¼˜åŒ–è®­ç»ƒå‚æ•°ï¼ˆé˜²æ­¢OOMï¼‰")
    
    # å…³é”®ä¿®æ”¹ï¼šé™ä½è¿™äº›å‚æ•°
    param.HyperParameter.batch_size = 4  # ä»24é™åˆ°4
    param.HyperParameter.channels_in = 5
    param.Simulation.emitter_av = 12  # ä»15é™åˆ°12
    
    print(f"  âœ“ Batch size: {param.HyperParameter.batch_size} (åŸ24ï¼Œé™ä½é˜²OOM)")
    print(f"  âœ“ å›¾åƒå°ºå¯¸: {param.Simulation.img_size} (ä¿æŒä¸å˜)")
    print(f"  âœ“ å¹³å‡å‘å°„ä½“: {param.Simulation.emitter_av} (åŸ15)")
    
    # ========== ç¬¬5æ­¥ï¼šè®¾ç½®è¾“å‡ºè·¯å¾„ï¼ˆå¸¦æ—¶é—´æˆ³é¿å…è¦†ç›–ï¼‰==========
    print(f"\n[5/7] é…ç½®è¾“å‡ºè·¯å¾„")
    model_dir = 'network/experiment1'
    ckpt_dir = 'network/experiment1'
    from_ckpt = False
    model_dir = Path(model_dir)
    
    if not model_dir.parents[0].is_dir():
        raise FileNotFoundError(
            f"The path to the directory of 'model_out' (and even its parent folder) could not be found.")
    else:
        if not model_dir.is_dir():
            model_dir.mkdir()
            print(f"Created directory, absolute path: {model_dir.resolve()}")
    
    # ä½¿ç”¨å¸¦æ—¥æœŸçš„æ–‡ä»¶å
    date_str = datetime.datetime.now().strftime("%Y%m%d_%H%M")
    model_out = Path(model_dir) / f'model_dh_{date_str}.pt'
    ckpt_path = Path(ckpt_dir) / f'ckpt_dh_{date_str}.pt'
    
    param.InOut.experiment_out = str(model_dir)
    
    # ä¿å­˜å‚æ•°åˆ°å¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶
    param_run_path = Path(model_out).parents[0] / f'param_dh_{date_str}.yaml'
    param_io.save_params(param_run_path, param)
    
    print(f"  âœ“ æ¨¡å‹å°†ä¿å­˜: {model_out}")
    print(f"  âœ“ Checkpoint: {ckpt_path}")
    print(f"  âœ“ å‚æ•°å·²ä¿å­˜: {param_run_path}")
    
    # ========== ç¬¬6æ­¥ï¼šGPUæ£€æŸ¥ ==========
    print(f"\n[6/7] GPUçŠ¶æ€æ£€æŸ¥")
    import torch
    if not torch.cuda.is_available():
        raise RuntimeError("âŒ GPUä¸å¯ç”¨")
    
    torch.cuda.empty_cache()
    gpu_props = torch.cuda.get_device_properties(0)
    total_mem = gpu_props.total_memory / (1024**3)
    used_mem = torch.cuda.memory_allocated(0) / (1024**3)
    
    print(f"  âœ“ GPU: {gpu_props.name}")
    print(f"  âœ“ æ€»å†…å­˜: {total_mem:.2f} GB")
    print(f"  âœ“ å·²ä½¿ç”¨: {used_mem:.2f} GB")
    print(f"  âœ“ å¯ç”¨: {total_mem - used_mem:.2f} GB")
    
    if total_mem < 6:
        print(f"  âš ï¸ è­¦å‘Šï¼šGPUå†…å­˜è¾ƒå°ï¼Œè‡ªåŠ¨é™ä½batch_sizeåˆ°2")
        param.HyperParameter.batch_size = 2
    
    # ========== ç¬¬7æ­¥ï¼šè®¾ç½®æ¨¡æ‹Ÿå™¨ ==========
    print(f"\n[7/7] åˆå§‹åŒ–æ¨¡æ‹Ÿå™¨")
    import generic.random_simulation
    
    try:
        sim_train, sim_test = generic.random_simulation.setup_random_simulation(param)
        print(f"  âœ“ æ¨¡æ‹Ÿå™¨è®¾ç½®å®Œæˆ")
    except Exception as e:
        print(f"  âŒ æ¨¡æ‹Ÿå™¨è®¾ç½®å¤±è´¥: {e}")
        raise
    
    # ========== å¼€å§‹è®­ç»ƒè®¾ç½® ==========
    print("\n" + "="*80)
    print("ğŸš€ å¼€å§‹è®­ç»ƒè®¾ç½®")
    print("="*80)
    
    simulator = sim_train
    from decode.neuralfitter.train import live_engine
    from decode.neuralfitter.utils import logger as logger_utils
    
    device = 'cuda'
    logger = [logger_utils.SummaryWriter(log_dir='logs',
                                         filter_keys=["dx_red_mu", "dx_red_sig",
                                                      "dy_red_mu", "dy_red_sig",
                                                      "dz_red_mu", "dz_red_sig",
                                                      "dphot_red_mu", "dphot_red_sig",
                                                      "f1",
                                                      ]),
              logger_utils.DictLogger()]
    logger = logger_utils.MultiLogger(logger)
    
    ds_train, ds_test, model, model_ls, grad_mod, post_processor, matcher, ckpt = \
        setup_trainer(sim_train, sim_test, logger, model_out, ckpt_path, device, param)
    
    dl_train, dl_test = live_engine.setup_dataloader(param, ds_train, ds_test)
    
    import Choose_Device as Device
    import Net.CNNLSTM as LS
    
    # æ›¿æ¢ä¸ºä½ çš„è‡ªå®šä¹‰æ¨¡å‹
    model = AdaptiveCNNBiLSTM(
        in_channels=1, 
        out_channels=11, 
        seq_len=param.HyperParameter.channels_in,
        pad_convs=True, 
        depth=2, 
        initial_features=48,
        sigma_eps_default=0.005,
        dropout_config={
            'spatial_dropout': True,
            'bottleneck_p': 0.3,
            'lstm_p': 0.25,  
            'output_p': 0.15,
            'adaptive': True
        }
    ).to(Device.device)
    
    optimizer = torch.optim.AdamW(model.parameters(), lr=0.0006, weight_decay=0.1)
    
    # âœ¨ é‡è¦ï¼šä½¿ç”¨paramä¸­å·²ç»è®¾ç½®å¥½çš„PSFå¯¹è±¡
    psf = param.Simulation.psf_type.init_spline(
        xextent=param.Simulation.psf_extent[0],
        yextent=param.Simulation.psf_extent[1],
        img_shape=param.Simulation.img_size,
        device=param.Hardware.device_simulation,
        roi_size=param.Simulation.roi_size,
        roi_auto_center=param.Simulation.roi_auto_center
    )
    
    criterion = LossFunc(
        xextent=param.Simulation.psf_extent[0],
        yextent=param.Simulation.psf_extent[1],
        img_shape=param.Simulation.img_size,
        psf=psf,
        device=param.Hardware.device_simulation,
    )
    
    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, gamma=0.9, step_size=10)
    
    converges = False
    n = 0
    n_max = param.HyperParameter.auto_restart_param.num_restarts
    
    if from_ckpt:
        ckpt = decode.utils.checkpoint.CheckPoint.load(param.InOut.checkpoint_init)
        model.load_state_dict(ckpt.model_state)
        optimizer.load_state_dict(ckpt.optimizer_state)
        lr_scheduler.load_state_dict(ckpt.lr_sched_state)
        epoch0 = ckpt.step + 1
        model = model.train()
        print(f'Resuming training from checkpoint')
    else:
        epoch0 = 0
        while not converges and n < n_max:
            n += 1
            
            conv_check = decode.neuralfitter.utils.progress.GMMHeuristicCheck(
                ref_epoch=1,
                emitter_avg=sim_train.em_sampler.em_avg,
                threshold=param.HyperParameter.auto_restart_param.restart_treshold,
            )
            
            # åˆå§‹åŒ–ç§‘å­¦ç›‘æ§å™¨
            monitor = OverfittingMonitor(
                patience=param.HyperParameter.epochs,
                min_epochs=5
            )
            
            print("\n" + "="*80)
            print("ğŸš€ ç§‘å­¦åŒ–è®­ç»ƒç›‘æ§ç³»ç»Ÿ")
            print("="*80)
            print(f"è®­ç»ƒè½®æ•°: {param.HyperParameter.epochs}")
            print(f"Batch size: {param.HyperParameter.batch_size}")
            print(f"Learning rate: {optimizer.param_groups[0]['lr']:.6f}")
            print(f"Early Stopping Patience: {monitor.patience}")
            print("="*80 + "\n")
            
            for i in range(epoch0, param.HyperParameter.epochs):
                logger.add_scalar('learning/learning_rate', optimizer.param_groups[0]['lr'], i)
                
                train_loss = train(
                    model=model,
                    optimizer=optimizer,
                    loss=criterion,
                    dataloader=dl_train,
                    grad_rescale=param.HyperParameter.moeller_gradient_rescale,
                    grad_mod=param.HyperParameter.grad_mod,
                    epoch=i,
                    device=torch.device(param.Hardware.device),
                    logger=logger
                )
                
                val_loss, test_out = test_simple(
                    model=model, 
                    loss=criterion, 
                    dataloader=dl_test,
                    epoch=i,
                    device=torch.device(param.Hardware.device)
                )
                
                monitor.update(train_loss, val_loss)
                status, metrics = monitor.get_status(i)
                
                # è¯¦ç»†æ‰“å°
                print(f"\n{'='*80}")
                print(f"ğŸ“Š Epoch {i+1}/{param.HyperParameter.epochs} - {status}")
                print(f"{'='*80}")
                print(f"  Train Loss:     {metrics['train_loss']:.6f}")
                print(f"  Val Loss:       {metrics['val_loss']:.6f}")
                print(f"  Absolute Gap:   {metrics['absolute_gap']:.6f}")
                print(f"  Relative Gap:   {metrics['relative_gap']:.4%}")
                print(f"  Val Trend:      {metrics['val_trend']:+.6f} {'ğŸ“ˆ' if metrics['val_trend'] > 0 else 'ğŸ“‰'}")
                print(f"  Gap Trend:      {metrics['gap_trend']:+.6f} {'ğŸ“ˆ' if metrics['gap_trend'] > 0 else 'ğŸ“‰'}")
                print(f"  Best Val Loss:  {monitor.best_val_loss:.6f}")
                print(f"  No Improve:     {monitor.epochs_no_improve} epochs")
                print(f"{'='*80}\n")
                
                # è®°å½•åˆ°logger
                logger.add_scalar('monitor/relative_gap', metrics['relative_gap'], i)
                logger.add_scalar('monitor/val_trend', metrics['val_trend'], i)
                logger.add_scalar('monitor/gap_trend', metrics['gap_trend'], i)
                
                """Post-Process and Evaluate"""
                decode.neuralfitter.train.live_engine.log_train_val_progress.post_process_log_test(
                    loss_cmp=test_out.loss,
                    loss_scalar=val_loss,
                    x=test_out.x,
                    y_out=test_out.y_out,
                    y_tar=test_out.y_tar,
                    weight=test_out.weight,
                    em_tar=ds_test.emitter,
                    px_border=-0.5,
                    px_size=1.,
                    post_processor=post_processor,
                    matcher=matcher,
                    logger=logger,
                    step=i
                )
                
                if isinstance(lr_scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):
                    lr_scheduler.step(val_loss)
                else:
                    lr_scheduler.step()
                
                model_ls.save(model, None)
                ckpt.dump(model.state_dict(), optimizer.state_dict(), lr_scheduler.state_dict(),
                        log=logger.logger[1].log_dict, step=i)
                
                # Early Stopping æ£€æŸ¥
                if monitor.should_stop(i):
                    print("\n" + "="*80)
                    print("ğŸ›‘ Early Stopping Triggered")
                    print(f"éªŒè¯æŸå¤±å·² {monitor.patience} è½®æœªæ”¹å–„ï¼Œæå‰åœæ­¢è®­ç»ƒ")
                    print("="*80 + "\n")
                    break
                
                """Draw new samples"""
                if param.Simulation.mode in 'acquisition':
                    del ds_train._frames
                    del ds_train._emitter
                    del ds_train._bg_frames
                    del ds_train._nobg_frames
                    ds_train.sample(True)
                elif param.Simulation.mode != 'samples':
                    raise ValueError
        
            # ===== è®­ç»ƒæ€»ç»“ =====
            print("\n" + "="*80)
            print("ğŸ“ è®­ç»ƒå®Œæˆ - ç§‘å­¦è¯„ä¼°æŠ¥å‘Š")
            print("="*80)
            
            summary = monitor.get_summary()
            if summary:
                print(f"\nğŸ“Š ç»Ÿè®¡æŒ‡æ ‡:")
                print(f"  å¹³å‡è®­ç»ƒæŸå¤±:     {summary['avg_train_loss']:.6f}")
                print(f"  å¹³å‡éªŒè¯æŸå¤±:     {summary['avg_val_loss']:.6f}")
                print(f"  å¹³å‡ç›¸å¯¹Gap:      {summary['avg_relative_gap']:.4%}")
                print(f"  æœ€ä½³éªŒè¯æŸå¤±:     {summary['min_val_loss']:.6f} (Epoch {summary['best_epoch']})")
                
                print(f"\nğŸ“Š æœ€ç»ˆæŒ‡æ ‡:")
                print(f"  æœ€ç»ˆè®­ç»ƒæŸå¤±:     {summary['final_train_loss']:.6f}")
                print(f"  æœ€ç»ˆéªŒè¯æŸå¤±:     {summary['final_val_loss']:.6f}")
                print(f"  æœ€ç»ˆç›¸å¯¹Gap:      {summary['final_relative_gap']:.4%}")
                
                print(f"\nğŸ¯ æ”¶æ•›è´¨é‡è¯„åˆ†:   {summary['convergence_score']:.1f}/100")
                
                # ç»™å‡ºå»ºè®®
                print(f"\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
                if summary['convergence_score'] >= 80:
                    print("  âœ… è®­ç»ƒæ•ˆæœä¼˜ç§€ï¼Œæ¨¡å‹å·²è‰¯å¥½æ”¶æ•›")
                elif summary['convergence_score'] >= 60:
                    print("  âš ï¸  è®­ç»ƒæ•ˆæœè‰¯å¥½ï¼Œä½†ä»æœ‰ä¼˜åŒ–ç©ºé—´")
                    if summary['final_relative_gap'] > 0.15:
                        print("  â†’ å»ºè®®å¢å¤§ dropout ç‡æˆ–ä½¿ç”¨æ›´å¼ºçš„æ­£åˆ™åŒ–")
                else:
                    print("  âŒ è®­ç»ƒæ•ˆæœæ¬ ä½³ï¼Œå»ºè®®è°ƒæ•´è¶…å‚æ•°")
                    if summary['final_relative_gap'] > 0.20:
                        print("  â†’ ä¸¥é‡è¿‡æ‹Ÿåˆï¼Œå»ºè®®: 1) å¢å¤§dropout 2) å‡å°æ¨¡å‹å®¹é‡ 3) å¢åŠ æ•°æ®å¢å¼º")
                    elif summary['avg_train_loss'] > 0.5:
                        print("  â†’ æ¬ æ‹Ÿåˆï¼Œå»ºè®®: 1) å¢å¤§æ¨¡å‹å®¹é‡ 2) é™ä½dropout 3) è°ƒæ•´å­¦ä¹ ç‡")
                
                print("="*80 + "\n")
                
                # ä¿å­˜è¯¦ç»†ç»“æœ
                import json
                comparison_results = {
                    'train_losses': [float(l) for l in monitor.train_losses],
                    'val_losses': [float(l) for l in monitor.val_losses],
                    'relative_gaps': [float(g) for g in monitor.relative_gaps],
                    'summary': convert_to_serializable(summary)
                }
                
                result_file = model_dir / 'scientific_training_report.json'
                with open(result_file, 'w') as f:
                    json.dump(comparison_results, f, indent=2)
                
                print(f"ğŸ’¾ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {result_file}\n")
                
            break
    
    converges = True
    if converges:
        print("\n" + "="*80)
        print("âœ… è®­ç»ƒå®Œæˆï¼")
        print(f"â° å®Œæˆæ—¶é—´: {datetime.datetime.now()}")
        print(f"ğŸ“¦ æ¨¡å‹å·²ä¿å­˜: {model_out}")
        print("="*80)
    else:
        raise ValueError(f"Training aborted after {n_max} restarts. "
                         "You can try to reduce the learning rate by a factor of 2."
                         "\nIt is also possible that the simulated data is to challenging. "
                         "Check if your background and intensity values are correct "
                         "and possibly lower the average number of emitters.")